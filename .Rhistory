# Calcul du facteur de dispersion
dispersion_ratio <- summary(base_glm)$deviance / summary(base_glm)$df.residual
cat("Dispersion Ratio:", dispersion_ratio, "\n")
# Préparation des données pour le plot des résidus
df_resid <- data.frame(
fitted = fitted(base_glm),
pearson_res = residuals(base_glm, type = "pearson")
)
caption_resid <- str_wrap("Figure X: Résidus Pearson vs. Valeurs Prévues du modèle GLM Binomial simple.", width = 85)
p_residuals <- ggplot(df_resid, aes(x = fitted, y = pearson_res)) +
geom_point(color = "steelblue", alpha = 0.7) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Résidus vs Valeurs Prévues",
x = "Valeurs Prévues",
y = "Résidus Pearson",
caption = caption_resid
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5)
)
print(p_residuals)
df_resid$pearson_res <- residuals(base_glm, type = "pearson")
caption_qq <- str_wrap("Figure Y: Q-Q Plot des Résidus Pearson du modèle GLM Binomial simple.", width = 85)
p_qq <- ggplot(df_resid, aes(sample = pearson_res)) +
stat_qq(color = "steelblue", alpha = 0.7) +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Q-Q Plot des Résidus Pearson",
x = "Quantiles théoriques",
y = "Quantiles des résidus",
caption = caption_qq
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5)
)
print(p_qq)
# Calculer les quartiles et IQR
Q1 <- quantile(person_coin_summary$mean_success, 0.25)
Q3 <- quantile(person_coin_summary$mean_success, 0.75)
IQR_value <- Q3 - Q1
# Définir les seuils pour outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value
# Filtrer les observations considérées comme outliers
outliers_pc <- person_coin_summary %>%
filter(mean_success < lower_bound | mean_success > upper_bound)
print(outliers_pc)
# Calculer les distances de Cook pour toutes les observations
cooks_d <- cooks.distance(base_glm)
# Ajouter la distance de Cook aux données d'origine
df_with_cook <- df
df_with_cook$cooks_distance <- cooks_d
# Extraire les combinaisons person-coin des outliers
outlier_groups <- outliers_pc %>% select(person, coin)
# Filtrer les données originales pour les observations appartenant à ces groupes
df_outliers <- df_with_cook %>%
inner_join(outlier_groups, by = c("person", "coin"))
# Examiner les distances de Cook pour ces observations
df_outliers_selected <- df_outliers %>% select(person, coin, y, m, cooks_distance)
print(df_outliers_selected)
n <- nrow(df)
print(threshold <- 8/(n - 2*1))
# 0.01904 donc certain depasse ce seuil. Refit sans ces valeurs pour verifier si le resultat reste le meme
# Identifier les indices des observations avec une distance de Cook > seuil
influential_indices <- which(cooks_d > threshold)
# Supprimer ces observations du jeu de données original
df_cleaned <- df[-influential_indices, ]
# Ajuster un nouveau modèle GLM binomial simple sur les données nettoyées
refit_glm <- glm(cbind(y, m - y) ~ 1, family = binomial, data = df_cleaned)
# Afficher le résumé du nouveau modèle
summary(refit_glm)
refit_coef <- coef(refit_glm)
p_refit <- exp(refit_coef) / (1 + exp(refit_coef))
cat("Estimated same-side probability (model without influential points):", round(p_refit, 4), "\n")
#| label: "Normal linear model"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Création de la variable proportionnelle success
df$prop <- df$y / df$m
# Ajustement d'un modèle linéaire pondéré avec intercept seulement
# Poids = m (les constantes multiplicatives n'affectent pas les estimations)
wls_model <- lm(prop ~ 1, data = df, weights = df$m)
# Résumé du modèle WLS
summary(wls_model)
# Calcul de la probabilité estimée depuis le modèle WLS
p_wls <- coef(wls_model)[1]
cat("Estimated same-side probability using WLS:", round(p_wls, 4), "\n")
# Calcul de l'AIC pour les deux modèles
aic_glm <- AIC(base_glm)
aic_wls <- AIC(wls_model)
cat("AIC - GLM:", aic_glm, "\n")
cat("AIC - WLS:", aic_wls, "\n")
# Calcul de la BIC pour les deux modèles
bic_glm <- BIC(base_glm)
bic_wls <- BIC(wls_model)
cat("BIC - GLM:", bic_glm, "\n")
cat("BIC - WLS:", bic_wls, "\n")
#| label: "Normal linear model 2"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Ajuster un modèle gaussian avec poids pour reproduire WLS
glm_model_wls <- glm(prop ~ 1, family = gaussian, weights = m, data = df)
diag_wls <- glm.diag(glm_model_wls)
glm.diag.plots(glm_model_wls)
#| label: "Read the data"
#| echo: false
#| message: false
#| warning: false
#| error: false
library(ggplot2)
library(dplyr)
library(stringr)
library(SMPracticals)
set.seed(12345)
df <- read.csv("data-agg.csv",header=T)
n <- nrow(df)
df1 <- df[,-c(2,4)] # heads to heads
df2 <- df[,-c(1,3)] # tails to heads
df2[,1] <- df2[,2]-df2[,1] # tails to tails
names(df1) <- names(df2) <- c("y","m","person","coin")
start <- rep(c("heads","tails"),c(n,n))
df <- rbind(df1,df2)
df$person <- factor(df$person)
df$coin <- factor(df$coin)
df$start <- factor(start)
head(df)
head(df1)
head(df2)
#| label: "Global analysis"
#| echo: false
#| message: false
#| warning: false
#| error: false
### Quick overview of the data
num_persons <- length(unique(df$person))
num_coins <- length(unique(df$coin))
cat("Number of persons:", num_persons, "\n")
cat("Number of coins:", num_coins, "\n")
### Histogram of proportions
df$success <- df$y / df$m
df_heads <- subset(df, start == "heads")
df_tails <- subset(df, start == "tails")
caption_p_general <- str_wrap("Figure 1: Histogram of the success proportions for head starting and tail starting.", width = 85)
p_general <- ggplot(df, aes(x = success)) +
geom_histogram(bins = 60, fill = "steelblue", color = "white", alpha = 0.8) +
facet_wrap(~ start, ncol = 2) +
labs(
title = "Distribution of same-side proportions",
x = "Same-side proportion",
y = "Count",
caption = caption_p_general
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5),
legend.title = element_text(hjust = 0.5),
legend.text = element_text(hjust = 0.5)
)
# Calcul des statistiques par groupe 'start'
stats <- df %>%
group_by(start) %>%
summarize(
mu = mean(success, na.rm = TRUE),
sigma = sd(success, na.rm = TRUE),
.groups = "drop"
)
p_general +
geom_text(
data = stats,
aes(
x = 0.68,
y = Inf,
label = paste0(
"atop(hat(mu) == ", round(mu, 3),
", hat(sigma) == ", round(sigma, 3), ")"
)
),
parse = TRUE,
hjust = 1.1, vjust = 1.1,
size = 3,
color = "black",
inherit.aes = FALSE
)
#| label: "Analysis by person"
#| echo: false
#| message: false
#| warning: false
#| error: false
### (a) Summary of total flips and success by person
person_summary <- df %>%
group_by(person) %>%
summarize(
total_flips = sum(m),
mean_success = round(mean(success, na.rm = TRUE), 3),
.groups = "drop"
) %>%
arrange(mean_success)
print(person_summary)
### (b) Boxplot by person
caption_p_person = str_wrap("Figure 2: Boxplot of the success proportions by person.", width = 85)
p_person <- ggplot(person_summary, aes(x = "", y = mean_success)) +
geom_boxplot(
width = 0.1,
fill = "grey",
alpha = 0.7,
outlier.color = "red"
) +
labs(
title   = "Distribution of Success Proportion across Persons",
x = "Person",
y       = "Success Proportion",
caption = caption_p_person
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5),
legend.title = element_text(hjust = 0.5),
legend.text = element_text(hjust = 0.5)
)
print(p_person)
#| label: "Analysis by person"
#| echo: false
#| message: false
#| warning: false
#| error: false
### (a) Summary of total flips and success by person
coin_summary <- df %>%
group_by(coin) %>%
summarize(
total_flips = sum(m),
mean_success = round(mean(success, na.rm = TRUE), 3),
.groups = "drop"
) %>%
arrange(mean_success)
print(coin_summary)
### (b) Boxplot by person
caption_p_coin = str_wrap("Figure 3: Boxplot of the success proportions by coin.", width = 85)
p_coin <- ggplot(coin_summary, aes(x = "", y = mean_success)) +
geom_boxplot(
width = 0.1,
fill = "grey",
alpha = 0.7,
outlier.color = "red"
) +
labs(
title   = "Distribution of Success Proportion across Coins",
x = "Coin",
y       = "Success Proportion",
caption = caption_p_coin
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5),
legend.title = element_text(hjust = 0.5),
legend.text = element_text(hjust = 0.5)
)
print(p_coin)
#| label: "Analysis by person-coin"
#| echo: false
#| message: false
#| warning: false
#| error: false
person_coin_summary <- df %>%
group_by(person, coin) %>%
summarize(
total_flips = sum(m),
mean_success = round(mean(success, na.rm = TRUE), 3),
.groups = "drop"
) %>%
arrange(mean_success)
print(person_coin_summary)
### (b) Boxplot by person-coin
caption_p_person_coin = str_wrap("Figure 4: Boxplot of the success proportions by coin and person.", width = 85)
p_person_coin <- ggplot(person_coin_summary, aes(x = "", y = mean_success)) +
geom_boxplot(
width = 0.1,
fill = "grey",
alpha = 0.7,
outlier.color = "red"
) +
labs(
title   = "Distribution of Success Proportion across Coins-Persons",
x = "Coin-Person",
y       = "Success Proportion",
caption = caption_p_person_coin
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5),
legend.title = element_text(hjust = 0.5),
legend.text = element_text(hjust = 0.5)
)
print(p_person_coin)
#| label: "Violin Plot"
#| echo: false
#| message: false
#| warning: false
#| error: false
violin_data <- data.frame(
category = factor(c(rep("person", nrow(person_summary)),
rep("coin", nrow(coin_summary)),
rep("person_coin", nrow(person_coin_summary)))),
mean_success = c(person_summary$mean_success,
coin_summary$mean_success,
person_coin_summary$mean_success)
)
# Définition de la légende
caption_violin <- str_wrap(
"Figure 5: Violin plots with boxplots of the distribution of success proportions for persons, coins, and person-coin combinations.",
width = 85
)
# Création du graphique à violon avec boxplot superposé et facettes
p_violin <- ggplot(violin_data, aes(x = "", y = mean_success)) +
geom_violin(fill = "steelblue", color = "white", alpha = 0.8) +
geom_boxplot(width = 0.1, fill = "lightgrey", color = "black", outlier.color = "red") +
facet_wrap(~ category) +
labs(
title = "Distribution of Success Proportions",
x = "",
y = "Success Proportion",
caption = caption_violin
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5),
legend.title = element_text(hjust = 0.5),
legend.text = element_text(hjust = 0.5),
strip.background = element_rect(fill = "grey90"),
strip.text = element_text(face = "bold")
)
print(p_violin)
#| label: "Temporal analysis"
#| echo: false
#| message: false
#| warning: false
#| error: false
df_time <- read.csv("df-time-agg.csv", header = TRUE)
df_time <- df_time[, c("same_side", "agg")]
df_time <- df_time %>%
group_by(agg) %>%
summarize(mean_same_side = mean(same_side, na.rm = TRUE)) %>%
ungroup()
acf_result <- acf(df_time$mean_same_side, plot = FALSE)
print(acf_result)
cor_result <- cor(df_time$agg, df_time$mean_same_side, use = "complete.obs")
print(cor_result)
acf(df_time$mean_same_side, main="Autocorrélation de mean_same_side")
#| label: "GLM Binomial"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Ajustement du modèle GLM binomial simple
base_glm <- glm(cbind(y, m - y) ~ 1, family = binomial, data = df)
# Résumé du modèle pour voir les résultats
summary(base_glm)
base_coef <- coef(base_glm)
p_initial <- exp(base_coef) / (1 + exp(base_coef))
cat("Estimated same-side probability (initial model):", round(p_initial, 4), "\n")
# Calcul du facteur de dispersion
dispersion_ratio <- summary(base_glm)$deviance / summary(base_glm)$df.residual
cat("Dispersion Ratio:", dispersion_ratio, "\n")
# Préparation des données pour le plot des résidus
df_resid <- data.frame(
fitted = fitted(base_glm),
pearson_res = residuals(base_glm, type = "pearson")
)
caption_resid <- str_wrap("Figure X: Résidus Pearson vs. Valeurs Prévues du modèle GLM Binomial simple.", width = 85)
p_residuals <- ggplot(df_resid, aes(x = fitted, y = pearson_res)) +
geom_point(color = "steelblue", alpha = 0.7) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Résidus vs Valeurs Prévues",
x = "Valeurs Prévues",
y = "Résidus Pearson",
caption = caption_resid
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5)
)
print(p_residuals)
df_resid$pearson_res <- residuals(base_glm, type = "pearson")
caption_qq <- str_wrap("Figure Y: Q-Q Plot des Résidus Pearson du modèle GLM Binomial simple.", width = 85)
p_qq <- ggplot(df_resid, aes(sample = pearson_res)) +
stat_qq(color = "steelblue", alpha = 0.7) +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Q-Q Plot des Résidus Pearson",
x = "Quantiles théoriques",
y = "Quantiles des résidus",
caption = caption_qq
) +
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0.5)
)
print(p_qq)
# Calculer les quartiles et IQR
Q1 <- quantile(person_coin_summary$mean_success, 0.25)
Q3 <- quantile(person_coin_summary$mean_success, 0.75)
IQR_value <- Q3 - Q1
# Définir les seuils pour outliers
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value
# Filtrer les observations considérées comme outliers
outliers_pc <- person_coin_summary %>%
filter(mean_success < lower_bound | mean_success > upper_bound)
print(outliers_pc)
# Calculer les distances de Cook pour toutes les observations
cooks_d <- cooks.distance(base_glm)
# Ajouter la distance de Cook aux données d'origine
df_with_cook <- df
df_with_cook$cooks_distance <- cooks_d
# Extraire les combinaisons person-coin des outliers
outlier_groups <- outliers_pc %>% select(person, coin)
# Filtrer les données originales pour les observations appartenant à ces groupes
df_outliers <- df_with_cook %>%
inner_join(outlier_groups, by = c("person", "coin"))
# Examiner les distances de Cook pour ces observations
df_outliers_selected <- df_outliers %>% select(person, coin, y, m, cooks_distance)
print(df_outliers_selected)
n <- nrow(df)
print(threshold <- 8/(n - 2*1))
# 0.01904 donc certain depasse ce seuil. Refit sans ces valeurs pour verifier si le resultat reste le meme
# Identifier les indices des observations avec une distance de Cook > seuil
influential_indices <- which(cooks_d > threshold)
# Supprimer ces observations du jeu de données original
df_cleaned <- df[-influential_indices, ]
# Ajuster un nouveau modèle GLM binomial simple sur les données nettoyées
refit_glm <- glm(cbind(y, m - y) ~ 1, family = binomial, data = df_cleaned)
# Afficher le résumé du nouveau modèle
summary(refit_glm)
refit_coef <- coef(refit_glm)
p_refit <- exp(refit_coef) / (1 + exp(refit_coef))
cat("Estimated same-side probability (model without influential points):", round(p_refit, 4), "\n")
#| label: "Normal linear model"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Création de la variable proportionnelle success
df$prop <- df$y / df$m
# Ajustement d'un modèle linéaire pondéré avec intercept seulement
# Poids = m (les constantes multiplicatives n'affectent pas les estimations)
wls_model <- lm(prop ~ 1, data = df, weights = df$m)
# Résumé du modèle WLS
summary(wls_model)
# Calcul de la probabilité estimée depuis le modèle WLS
p_wls <- coef(wls_model)[1]
cat("Estimated same-side probability using WLS:", round(p_wls, 4), "\n")
# Calcul de l'AIC pour les deux modèles
aic_glm <- AIC(base_glm)
aic_wls <- AIC(wls_model)
cat("AIC - GLM:", aic_glm, "\n")
cat("AIC - WLS:", aic_wls, "\n")
# Calcul de la BIC pour les deux modèles
bic_glm <- BIC(base_glm)
bic_wls <- BIC(wls_model)
cat("BIC - GLM:", bic_glm, "\n")
cat("BIC - WLS:", bic_wls, "\n")
#| label: "Normal linear model 2"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Ajuster un modèle gaussian avec poids pour reproduire WLS
glm_model_wls <- glm(prop ~ 1, family = gaussian, weights = m, data = df)
diag_wls <- glm.diag(glm_model_wls)
glm.diag.plots(glm_model_wls)
#| label: "Normal linear model 2"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Ajuster un modèle gaussian avec poids pour reproduire WLS
glm_model_wls <- glm(prop ~ 1, family = gaussian, weights = m, data = df)
summary(glm_model_wls)
#| label: "Normal linear model"
#| echo: false
#| message: false
#| warning: false
#| error: false
# Création de la variable proportionnelle success
df$prop <- df$y / df$m
# Ajustement d'un modèle linéaire pondéré avec intercept seulement
# Poids = m (les constantes multiplicatives n'affectent pas les estimations)
wls_model <- lm(prop ~ 1, data = df, weights = df$m)
# Résumé du modèle WLS
summary(wls_model)
# Calcul de la probabilité estimée depuis le modèle WLS
p_wls <- coef(wls_model)[1]
cat("Estimated same-side probability using WLS:", round(p_wls, 4), "\n")
# Ajuster un modèle gaussian avec poids pour reproduire WLS
glm_model_wls <- glm(prop ~ 1, family = gaussian, weights = m, data = df)
summary(glm_model_wls)
